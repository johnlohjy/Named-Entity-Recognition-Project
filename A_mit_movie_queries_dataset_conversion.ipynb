{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "curr_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_queries_filepath = os.path.join(curr_dir,'training_set','movie_queries.txt').replace('\\\\','/')\n",
    "movie_queries_training_dataset_filepath = os.path.join(curr_dir,'training_set','movie_queries_training_dataset.csv').replace('\\\\','/')\n",
    "index_to_target_filepath = os.path.join(curr_dir,'index_converter','index_to_target.txt').replace('\\\\','/')\n",
    "target_to_index_filepath = os.path.join(curr_dir,'index_converter','target_to_index.txt').replace('\\\\','/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the training set online and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = 'https://groups.csail.mit.edu/sls/downloads/movie/engtrain.bio'\n",
    "urllib.request.urlretrieve(url, movie_queries_filepath)\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(movie_queries_filepath) as f:\n",
    "    content = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of lines in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O\\twhat\\n',\n",
       " 'O\\tmovies\\n',\n",
       " 'O\\tstar\\n',\n",
       " 'B-ACTOR\\tbruce\\n',\n",
       " 'I-ACTOR\\twillis\\n',\n",
       " '\\n',\n",
       " 'O\\tshow\\n',\n",
       " 'O\\tme\\n',\n",
       " 'O\\tfilms\\n',\n",
       " 'O\\twith\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of splitting text into labels and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'what']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0].strip('\\n').split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[5].strip('\\n').split('\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Splitting text into words and labels\n",
    "\n",
    "Characters of words that are not letters, numbers or punctuation are removed as this will impact\n",
    "* Sentence Tokenization\n",
    "* Word Tokenization\n",
    "* Word Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "targets = []\n",
    "\n",
    "temp_sentence = []\n",
    "temp_targets = []\n",
    "\n",
    "#Counter just acts as an index reference\n",
    "counter=0\n",
    "#Iterate over the list of extracted raw data.\n",
    "for i in content:\n",
    "    counter+=1\n",
    "    #Split the raw extracted element data into its target label and word. Ex. O\\twhat\\n -> ['O','what']\n",
    "    extracted = i.strip('\\n').split('\\t')\n",
    "    \n",
    "    #If the length of the split i.e.['O','what'] is 2, it means we are still iterating over a sentence\n",
    "    if len(extracted)==2:\n",
    "        #remove all characters that are not letters, numbers or punctuaton from the split\n",
    "        clean = re.sub('[^a-zA-Z0-9.,]+','',extracted[1])\n",
    "        #If the split does not contain letters, numbers or punctuation at all we remove it\n",
    "        if len(clean)==0:\n",
    "            print('Anomaly found {} at index {}'.format(extracted[1],counter-1))\n",
    "            continue\n",
    "        #Append the target label and word to a temp array after it has been processed\n",
    "        temp_targets.append(extracted[0])\n",
    "        temp_sentence.append(clean)\n",
    "\n",
    "    #This code block will run only when we hit an empty split. Ex \\n -> [''], where \\n denotes the start of \n",
    "    #a new line. This means that we have finished iterating over a single sentence\n",
    "    else:\n",
    "        #Append the temp_targets array to the targets array, and join all the elements (words) in the temp_sentence array\n",
    "        #and append it to the sentences array.\n",
    "        targets.append(temp_targets)\n",
    "        sentences.append(' '.join(temp_sentence))\n",
    "        #Reset the temp arrays\n",
    "        temp_sentence = []\n",
    "        temp_targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what movies star bruce willis'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'B-ACTOR', 'I-ACTOR']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform part of speech tagging\n",
    "\n",
    "Help model to learn the grammar of movie queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add pos tags to each word of a sentence\n",
    "sent_num = 0\n",
    "pos_dict = {}\n",
    "for sentence in sentences:\n",
    "    pos_dict[sent_num] = nltk.pos_tag(word_tokenize(sentence))\n",
    "    sent_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP'),\n",
       " ('movies', 'NNS'),\n",
       " ('star', 'VBP'),\n",
       " ('bruce', 'NN'),\n",
       " ('willis', 'NN')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the punctuation\n",
    "\n",
    "We need to remove these stray punctuations as it directly impacts word vectorization, they cannot be vectorized. We preserved the punctuation for part of speech tagging as it is key in sentence structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found stray punctuation\n",
      "Original: ,\n",
      "New: \n",
      "\n",
      "#################\n"
     ]
    }
   ],
   "source": [
    "#Remove stray . , from words using re sub. If the word value of the tuple only contains . , then remove it\n",
    "for key,value in pos_dict.items():\n",
    "    cleaned = []\n",
    "    for pos_tuple in value:\n",
    "        word_value, tag_value = pos_tuple\n",
    "        checked = re.sub('[^a-zA-Z0-9]+','',word_value) \n",
    "        if len(checked)!=len(word_value):\n",
    "            print('Found stray punctuation')\n",
    "            print('Original: {}'.format(word_value))\n",
    "            print('New: {}'.format(checked))\n",
    "            print('')\n",
    "            print('#################')\n",
    "        if len(checked) == 0 :\n",
    "            continue\n",
    "        else:\n",
    "            pos_tuple = tuple([checked, tag_value])\n",
    "            cleaned.append(pos_tuple)\n",
    "\n",
    "    pos_dict[key] = cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making words and targets equal (if needed)\n",
    "\n",
    "This is because the pos tagger may tokenize the words differently and result in an unequal length of words and corresponding targets. Examples can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence number 2212 in the pos tag has an unequal length of words and corresponding targets\n",
      "Sentence number 2526 in the pos tag has an unequal length of words and corresponding targets\n",
      "Sentence number 3158 in the pos tag has an unequal length of words and corresponding targets\n",
      "Sentence number 3815 in the pos tag has an unequal length of words and corresponding targets\n",
      "Sentence number 9713 in the pos tag has an unequal length of words and corresponding targets\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for k,v in pos_dict.items():\n",
    "    if len(v)!=len(targets[counter]):\n",
    "        print('Sentence number {} in the pos tag has an unequal length of words and corresponding targets'.format(k))\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix sentence 2212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'was there a boxing movie with the song gonna fly now'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[2212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('was', 'VBD'),\n",
       " ('there', 'EX'),\n",
       " ('a', 'DT'),\n",
       " ('boxing', 'NN'),\n",
       " ('movie', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('song', 'NN'),\n",
       " ('gon', 'NN'),\n",
       " ('na', 'TO'),\n",
       " ('fly', 'VB'),\n",
       " ('now', 'RB')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict[2212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict[2212].pop(8)\n",
    "pos_dict[2212].pop(8)\n",
    "pos_dict[2212].insert(8,('gonna','NN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('was', 'VBD'),\n",
       " ('there', 'EX'),\n",
       " ('a', 'DT'),\n",
       " ('boxing', 'NN'),\n",
       " ('movie', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('song', 'NN'),\n",
       " ('gonna', 'NN'),\n",
       " ('fly', 'VB'),\n",
       " ('now', 'RB')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict[2212]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix sentence 2526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what movie uses the song i dont wanna miss a thing on its soundtrack'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[2526]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP'),\n",
       " ('movie', 'NN'),\n",
       " ('uses', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('song', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('dont', 'VBP'),\n",
       " ('wan', 'NN'),\n",
       " ('na', 'TO'),\n",
       " ('miss', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('thing', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('soundtrack', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict[2526]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict[2526].pop(7)\n",
    "pos_dict[2526].pop(7)\n",
    "pos_dict[2526].insert(7,('wanna','NN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP'),\n",
       " ('movie', 'NN'),\n",
       " ('uses', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('song', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('dont', 'VBP'),\n",
       " ('wanna', 'NN'),\n",
       " ('miss', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('thing', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('soundtrack', 'NN')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict[2526]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix sentence 3158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what the movie with you gotta friend in me'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[3158]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP'),\n",
       " ('the', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('got', 'VBP'),\n",
       " ('ta', 'JJ'),\n",
       " ('friend', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('me', 'PRP')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict[3158]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict[3158].pop(5)\n",
    "pos_dict[3158].pop(5)\n",
    "pos_dict[3158].insert(5,('gotta','VBP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP'),\n",
       " ('the', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('gotta', 'VBP'),\n",
       " ('friend', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('me', 'PRP')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict[3158]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix sentence 3815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id like to see the 1975 movie with the quote youre gonna need a bigger boat'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[3815]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('1975', 'CD'),\n",
       " ('movie', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('quote', 'JJ'),\n",
       " ('youre', 'NN'),\n",
       " ('gon', 'NN'),\n",
       " ('na', 'TO'),\n",
       " ('need', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('bigger', 'JJR'),\n",
       " ('boat', 'NN')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict[3815]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict[3815].pop(11)\n",
    "pos_dict[3815].pop(11)\n",
    "pos_dict[3815].insert(11,('gonna','NN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('1975', 'CD'),\n",
       " ('movie', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('quote', 'JJ'),\n",
       " ('youre', 'NN'),\n",
       " ('gonna', 'NN'),\n",
       " ('need', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('bigger', 'JJR'),\n",
       " ('boat', 'NN')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict[3815]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix sentence 9713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aguirre , wrath of god'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[9713]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aguirre', 'NN'), ('wrath', 'NN'), ('of', 'IN'), ('god', 'NN')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict[9713]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-TITLE', 'I-TITLE', 'I-TITLE', 'I-TITLE', 'I-TITLE']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[9713]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I-TITLE'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[9713].pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-TITLE', 'I-TITLE', 'I-TITLE', 'I-TITLE']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[9713]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change targets to extended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done to make adding the targets to the training dataframe easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_extended = []\n",
    "for i in targets:\n",
    "    targets_extended.extend(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating target dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [(k, *t) for k, v in pos_dict.items() for t in v]\n",
    "df_target = pd.DataFrame(L, columns=['sentence_no','word','pos'])\n",
    "df_target['target'] = targets_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_no</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what</td>\n",
       "      <td>WP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>movies</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>star</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bruce</td>\n",
       "      <td>NN</td>\n",
       "      <td>B-ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>willis</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-ACTOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_no    word  pos   target\n",
       "0            0    what   WP        O\n",
       "1            0  movies  NNS        O\n",
       "2            0    star  VBP        O\n",
       "3            0   bruce   NN  B-ACTOR\n",
       "4            0  willis   NN  I-ACTOR"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target.to_csv(movie_queries_training_dataset_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the targets\n",
    "\n",
    "This is to be used to convert targets to indexes vice-versa later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets = list(set(df_target['target'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-TITLE',\n",
       " 'B-TRAILER',\n",
       " 'O',\n",
       " 'B-TITLE',\n",
       " 'B-CHARACTER',\n",
       " 'I-RATINGS_AVERAGE',\n",
       " 'I-TRAILER',\n",
       " 'B-YEAR',\n",
       " 'I-SONG',\n",
       " 'B-RATING',\n",
       " 'I-DIRECTOR',\n",
       " 'I-YEAR',\n",
       " 'B-GENRE',\n",
       " 'I-RATING',\n",
       " 'B-PLOT',\n",
       " 'I-PLOT',\n",
       " 'I-GENRE',\n",
       " 'B-DIRECTOR',\n",
       " 'I-ACTOR',\n",
       " 'B-ACTOR',\n",
       " 'B-SONG',\n",
       " 'B-RATINGS_AVERAGE',\n",
       " 'B-REVIEW',\n",
       " 'I-REVIEW',\n",
       " 'I-CHARACTER']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_all_targets = sorted(all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ACTOR',\n",
       " 'B-CHARACTER',\n",
       " 'B-DIRECTOR',\n",
       " 'B-GENRE',\n",
       " 'B-PLOT',\n",
       " 'B-RATING',\n",
       " 'B-RATINGS_AVERAGE',\n",
       " 'B-REVIEW',\n",
       " 'B-SONG',\n",
       " 'B-TITLE',\n",
       " 'B-TRAILER',\n",
       " 'B-YEAR',\n",
       " 'I-ACTOR',\n",
       " 'I-CHARACTER',\n",
       " 'I-DIRECTOR',\n",
       " 'I-GENRE',\n",
       " 'I-PLOT',\n",
       " 'I-RATING',\n",
       " 'I-RATINGS_AVERAGE',\n",
       " 'I-REVIEW',\n",
       " 'I-SONG',\n",
       " 'I-TITLE',\n",
       " 'I-TRAILER',\n",
       " 'I-YEAR',\n",
       " 'O']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_all_targets.pop(-1)\n",
    "sorted_all_targets.insert(0, 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_to_index = {}\n",
    "counter = 0\n",
    "for i in sorted_all_targets:\n",
    "    target_to_index[i] = counter\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-ACTOR': 1,\n",
       " 'B-CHARACTER': 2,\n",
       " 'B-DIRECTOR': 3,\n",
       " 'B-GENRE': 4,\n",
       " 'B-PLOT': 5,\n",
       " 'B-RATING': 6,\n",
       " 'B-RATINGS_AVERAGE': 7,\n",
       " 'B-REVIEW': 8,\n",
       " 'B-SONG': 9,\n",
       " 'B-TITLE': 10,\n",
       " 'B-TRAILER': 11,\n",
       " 'B-YEAR': 12,\n",
       " 'I-ACTOR': 13,\n",
       " 'I-CHARACTER': 14,\n",
       " 'I-DIRECTOR': 15,\n",
       " 'I-GENRE': 16,\n",
       " 'I-PLOT': 17,\n",
       " 'I-RATING': 18,\n",
       " 'I-RATINGS_AVERAGE': 19,\n",
       " 'I-REVIEW': 20,\n",
       " 'I-SONG': 21,\n",
       " 'I-TITLE': 22,\n",
       " 'I-TRAILER': 23,\n",
       " 'I-YEAR': 24}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_target = dict([(value, key) for key, value in target_to_index.items()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-ACTOR',\n",
       " 2: 'B-CHARACTER',\n",
       " 3: 'B-DIRECTOR',\n",
       " 4: 'B-GENRE',\n",
       " 5: 'B-PLOT',\n",
       " 6: 'B-RATING',\n",
       " 7: 'B-RATINGS_AVERAGE',\n",
       " 8: 'B-REVIEW',\n",
       " 9: 'B-SONG',\n",
       " 10: 'B-TITLE',\n",
       " 11: 'B-TRAILER',\n",
       " 12: 'B-YEAR',\n",
       " 13: 'I-ACTOR',\n",
       " 14: 'I-CHARACTER',\n",
       " 15: 'I-DIRECTOR',\n",
       " 16: 'I-GENRE',\n",
       " 17: 'I-PLOT',\n",
       " 18: 'I-RATING',\n",
       " 19: 'I-RATINGS_AVERAGE',\n",
       " 20: 'I-REVIEW',\n",
       " 21: 'I-SONG',\n",
       " 22: 'I-TITLE',\n",
       " 23: 'I-TRAILER',\n",
       " 24: 'I-YEAR'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_to_index_filepath, \"wb\") as t:\n",
    "    pickle.dump(target_to_index, t)\n",
    "    \n",
    "with open(index_to_target_filepath, \"wb\") as t:\n",
    "    pickle.dump(index_to_target, t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
