{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "curr_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sets_filepath = os.path.join(curr_dir,'training_set','movie_queries_training_dataset.csv').replace('\\\\','/')\n",
    "word_vectors_filepath = os.path.join(curr_dir,'word_vector','word_vector.txt').replace('\\\\','/')\n",
    "target_to_index_filepath = os.path.join(curr_dir,'index_converter','target_to_index.txt').replace('\\\\','/')\n",
    "random_search_hist_filepath = os.path.join(curr_dir,'random_search_data','random_search_hist.txt').replace('\\\\','/')\n",
    "random_search_hyperparams_filepath = os.path.join(curr_dir,'random_search_data','random_search_hyperparams.txt').replace('\\\\','/')\n",
    "best_hyperparams_info_filepath = os.path.join(curr_dir,'random_search_data','best_hyperparameter_info.txt').replace('\\\\','/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.data import load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re \n",
    "from keras import backend as k\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, LSTM, Input, concatenate, TimeDistributed, Bidirectional, Masking\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.metrics import crf_viterbi_accuracy, crf_accuracy\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras.optimizers import Adam  \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, ParameterSampler, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You only need to run the cell below once, you can delete the cell below and across all notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('tagsets')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to convert categories to index\n",
    "with open(target_to_index_filepath, \"rb\") as t:\n",
    "    target_to_index = pickle.load(t)\n",
    "    \n",
    "f1_labels = list(target_to_index.values())\n",
    "f1_labels.pop(-1)\n",
    "\n",
    "#input_sequence for sentences, output_sequence for targets of sentences\n",
    "input_sequence = []\n",
    "output_sequence = []\n",
    "\n",
    "#Store grid search results\n",
    "random_search_hist = {}\n",
    "\n",
    "def base_model(units=50, optimizer='Adam', hidden_layers=2, activation_td ='relu', dropout=0.1, recurrent_dropout=0.1):\n",
    "    hidden_layers_stored = {}\n",
    "    counter=1\n",
    "    #k.clear_session() is necessary here to save memory\n",
    "    k.clear_session()\n",
    "    input = Input(shape=(x.shape[1],x.shape[-1]))\n",
    "    mask = Masking(mask_value=0.)(input)\n",
    "    for hl in range(hidden_layers):\n",
    "        if counter==1:\n",
    "            hidden_layers_stored['hl_{}'.format(counter)] = Bidirectional(LSTM(units=units, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout))(mask)  \n",
    "        else:\n",
    "            hidden_layers_stored['hl_{}'.format(counter)] = Bidirectional(LSTM(units=units, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout))(hidden_layers_stored['hl_{}'.format(counter-1)])\n",
    "        counter+=1\n",
    "    model_last_layer = TimeDistributed(Dense(50, activation=activation_td))(hidden_layers_stored['hl_{}'.format(counter-1)])  \n",
    "    crf = CRF(25)  \n",
    "    out = crf(model_last_layer)  \n",
    "    model_final = Model(input, out)\n",
    "    model_final.compile(optimizer=optimizer, loss=crf_loss, metrics=[crf_accuracy])\n",
    "    return model_final\n",
    "\n",
    "#Initialize the hyperparameter number for random cv\n",
    "hyperparam_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all possible pos tags\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "all_pos = list(tagdict.keys())\n",
    "\n",
    "all_pos_tags = []\n",
    "for pos in all_pos:\n",
    "    all_pos_tags.append('pos_'+pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read pre-processed dataset for training\n",
    "df = pd.read_csv(training_sets_filepath)\n",
    "df_target = df.copy()\n",
    "\n",
    "#Get list of words from dataframe\n",
    "tokenized_text = df['word'].tolist()\n",
    "\n",
    "word_vector_api_data = tokenized_text\n",
    "session = requests.Session()\n",
    "session.trust_env = False\n",
    "session.post('http://127.0.0.1:5000/word_vectorization', json = word_vector_api_data) #add proxies args if needed\n",
    "\n",
    "with open(word_vectors_filepath, \"rb\") as t:\n",
    "    word_vectors = pickle.load(t)\n",
    "\n",
    "#Add word featues to dataframe\n",
    "df['word_vec'] = word_vectors\n",
    "df = pd.get_dummies(df, columns=['pos'])\n",
    "\n",
    "#Add all pos columns and rearrange in fixed order for consistency\n",
    "df_cols = list(df.columns)\n",
    "add_pos_col = [add for add in all_pos_tags if add not in df_cols]\n",
    "\n",
    "for added_pos in add_pos_col:\n",
    "    df[added_pos] = 0\n",
    "\n",
    "arrange_df_cols = ['sentence_no','word','word_vec']\n",
    "for arrange_pos in all_pos_tags:\n",
    "    arrange_df_cols.append(arrange_pos)\n",
    "df = df.reindex(columns=arrange_df_cols)\n",
    "\n",
    "#Get the sentence feature vectors. Each sentence contains a list of all its word feature vectors.\n",
    "df = df.drop(columns=['word'])\n",
    "sentence_feature_vectors = {}\n",
    "for index,row in df.iterrows():\n",
    "    sentence_number = row[0]\n",
    "    word_feature_vector = np.concatenate((row[1:]), axis = None)\n",
    "    if sentence_number in sentence_feature_vectors.keys():\n",
    "        sentence_feature_vectors[sentence_number].append(word_feature_vector)\n",
    "    else:\n",
    "        sentence_feature_vectors[sentence_number] = [word_feature_vector]\n",
    "\n",
    "#Pad length for sentences and append to the input_sequence \n",
    "dummy_length = len(sentence_feature_vectors[1][0])\n",
    "for sentence in sentence_feature_vectors.values():\n",
    "    while len(sentence) < 80:\n",
    "        sentence.append(np.array([0 for zero in range(dummy_length)]))\n",
    "\n",
    "    input_sequence.append(np.array(sentence))\n",
    "\n",
    "#Add the target for each word of the sentence\n",
    "targets = {}\n",
    "for index,row in df_target.iterrows():\n",
    "    sentence_number = row[1]\n",
    "    word_target = row[-1]\n",
    "    if sentence_number in targets.keys():\n",
    "        targets[sentence_number].append(word_target)\n",
    "    else:\n",
    "        targets[sentence_number] = [word_target]\n",
    "\n",
    "#Pad length for sentences and append to output_sequence\n",
    "for sentence in targets.values():\n",
    "    sentence = [target_to_index[target] for target in sentence]\n",
    "    while len(sentence) < 80:\n",
    "        sentence.append(target_to_index['O'])\n",
    "\n",
    "    output_sequence.append(np.array(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(input_sequence)\n",
    "y = np.array(output_sequence)\n",
    "y = to_categorical(y, num_classes=25)\n",
    "x_s,y_s = shuffle(x,y,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue random cv\n",
    "\n",
    "1. Load the whole list of parameters and the random search hist\n",
    "2. Remove all the parameters that have been tried\n",
    "3. Set the parameter number to continue from where we left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(random_search_hyperparams_filepath, \"rb\") as t:\n",
    "    hyperparams_list = pickle.load(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(random_search_hist_filepath, \"rb\") as t:\n",
    "    random_search_hist = pickle.load(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(random_search_hist)):\n",
    "    hyperparams_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_number = len(random_search_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search Cross Validation (CV)\n",
    "\n",
    "Find the best combination of hyperparameters for the algorithm in order for it to best learn from our use case.\n",
    "\n",
    "The random search finds sets of random combination of hyperparameters for the model to iteratively test out. \n",
    "\n",
    "Cross validation is then used to evaluate the performance of the model. Cross validation splits the data into an arbitrary number of sets. For instance, it splits the data into 5 sets. On the first run it will be trained on set 1 to 4 and tested on 5. Next, it will be trained on set 2 to 5 and tested on 1, so on and so forth. \n",
    "\n",
    "This is effective in validating performance as it is tested on multiple sets of unseen data. If the model performs well during cross validation, chances are that it has learnt patterns that generalize well to our use case as it can predict unseen data well.\n",
    "\n",
    "**Random Search vs Grid Search**\n",
    "\n",
    "* Random Search is more feasible as grid search will run over **every** parameter aka, 1800 parameters! This will take up a very long time and thus, unfeasible. \n",
    "* Proven that it has a 95% probability of finding a combination of hyperparameters within the top 5% best performing combinations using 60 iterations.\n",
    "\n",
    "Libraries such as keras and sklearn do not provide random search cv for 3 dimensional inputs and outputs so custom random search cv code needs to be written.\n",
    "\n",
    "1. Generate a random set (45 sets) of parameters using sklearn's ParameterSampler class\n",
    "\n",
    "2. Manually split the data into 5 folds using subsetting \n",
    "\n",
    "3. Write code to train on 4 folds of training data and test on the last one, repeating this process 5 times where the test set is a new fold every iteration and the rest of the folds are the training data. The performance metric/result of the test set, f1 score, is saved to a list at every iteration. At the end of the iteration, the evaluated set of parameter, the average of the f1 scores and all the f1 scores are added to the dictionary\n",
    "\n",
    "*a condition is put to stop the cross validation for a set of parameter if its f1 score is below 0.7 after 2 iterations to save time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a measure of performance\n",
    "\n",
    "F1 Score Vs Accuracy\n",
    "\n",
    "Accuracy is a misleading indicator for imbalanced datasets. In our case 'O' entities makes up majority of all entities\n",
    "\n",
    "Example:\n",
    "\n",
    "* Positive class = Location\n",
    "* Negative class = Non Location\n",
    "\n",
    "\n",
    "Accuracy: (Number of Correct Predictions) / (Total Number of Predictions), (1 + 90)/(100), 91% \n",
    "\n",
    "We aim to predict location entities, however out of the 9 location entities we only predicted 1 correctly. Thus accuracy creates the illusion that our model performs very well by taking the correct predictions of the majority negative class into account.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Precision: (Number of Correct Positive Predictions) / (Total Number of Positive Predictions), (1)/(1+1), 50%\n",
    "\n",
    "Preicison measures the proportion of positive predictions made that are correct. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Recall: (Number of Correct Positive Predictions) / (Total Number of Positives), (1)/(1+8), 11%\n",
    "\n",
    "Recall measures the proportion of actual positives that were captured\n",
    "\n",
    "<br>\n",
    "\n",
    "F1 score is a combination of precision and recall, and is a much better reflection of a model's performance for predicting the positive class, which is the class we are aiming to predict\n",
    "\n",
    "The f1 macro score is used as it calculates the f1 score for each label and averages them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_hyperparams = [16, 32, 64, 128, 256]\n",
    "epochs_hyperparams = [30,50,80,100,150,200,250]\n",
    "units_hyperparams = [50, 100, 150, 200]\n",
    "optimizer_hyperparams = ['RMSprop', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "hidden_layers_hyperparams = [1, 2, 3]\n",
    "dropout_hyperparams = [0.1,0.2,0.3]\n",
    "recurrent_dropout_hyperparams = [0.1,0.2,0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_grid = dict(batch_size_hyperparams=batch_size_hyperparams, epochs_hyperparams=epochs_hyperparams, units_hyperparams=units_hyperparams, optimizer_hyperparams=optimizer_hyperparams, hidden_layers_hyperparams = hidden_layers_hyperparams, dropout_hyperparams=dropout_hyperparams, recurrent_dropout_hyperparams=recurrent_dropout_hyperparams)\n",
    "print(\"Random set of hyperparameters to generate from:\")\n",
    "hyperparams_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_hyperparams = ParameterSampler(hyperparams_grid, n_iter=60) \n",
    "hyperparams_list = list(random_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following combination of parameters is found to work quite well, which is why I added it in. You can remove it if you want to start afresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'units_hyperparams': 100, 'recurrent_dropout_hyperparams': 0.3, 'optimizer_hyperparams': 'Adadelta', 'hidden_layers_hyperparams': 1, 'epochs_hyperparams': 250, 'dropout_hyperparams': 0.2, 'batch_size_hyperparams': 32} in hyperparams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_list[0]={'units_hyperparams': 100, 'recurrent_dropout_hyperparams': 0.3, 'optimizer_hyperparams': 'Adadelta', 'hidden_layers_hyperparams': 1, 'epochs_hyperparams': 250, 'dropout_hyperparams': 0.2, 'batch_size_hyperparams': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random set of hyperparameters:\")\n",
    "hyperparams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(random_search_hyperparams_filepath, \"wb\") as t:\n",
    "    pickle.dump(hyperparams_list, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting cross validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = x_s[:1955]\n",
    "x_2 = x_s[1955:3910]\n",
    "x_3 = x_s[3910:5865]\n",
    "x_4 = x_s[5865:7820]\n",
    "x_5 = x_s[7820:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Each fold contains approx 1955 sentences:\")\n",
    "x_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = y_s[:1955]\n",
    "y_2 = y_s[1955:3910]\n",
    "y_3 = y_s[3910:5865]\n",
    "y_4 = y_s[5865:7820]\n",
    "y_5 = y_s[7820:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cv = [x_1,x_2,x_3,x_4,x_5]\n",
    "y_cv = [y_1,y_2,y_3,y_4,y_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hyperparam in hyperparams_list:\n",
    "    #If this is the first hyperparameter in the random search, don't load the random search history file \n",
    "    #because there won't be a file yet\n",
    "    if hyperparam_number!=0:\n",
    "        with open(random_search_hist_filepath, \"rb\") as t:\n",
    "            random_search_hist = pickle.load(t)\n",
    "            \n",
    "    #Stores information regarding the random cv of the hyperparameter\n",
    "    \n",
    "    temp_list = []\n",
    "    for cv in range(5):\n",
    "        print('#############################')\n",
    "        #Initializing the model with the hyperparameters to be evaluated\n",
    "        my_model = base_model(units=hyperparam['units_hyperparams'], optimizer=hyperparam['optimizer_hyperparams'], hidden_layers = hyperparam['hidden_layers_hyperparams'], dropout = hyperparam['dropout_hyperparams'], recurrent_dropout = hyperparam['recurrent_dropout_hyperparams'])\n",
    "        \n",
    "        #Selecting the x training set i.e. 4 training sets other than the training set at the current index, and\n",
    "        #respective y training set\n",
    "        select_xtraining_set = [train for i,train in enumerate(x_cv) if i!=cv]\n",
    "        xtrain_1 = select_xtraining_set[0]\n",
    "        xtrain_2 = select_xtraining_set[1]\n",
    "        xtrain_3 = select_xtraining_set[2]\n",
    "        xtrain_4 = select_xtraining_set[3]\n",
    "        xset_1 = np.append(xtrain_1,xtrain_2,axis=0)\n",
    "        xset_2 = np.append(xset_1,xtrain_3,axis=0)\n",
    "        xtraining_set = np.append(xset_2,xtrain_4,axis=0)\n",
    "        \n",
    "        select_ytraining_set = [train for i,train in enumerate(y_cv) if i!=cv]\n",
    "        ytrain_1 = select_ytraining_set[0]\n",
    "        ytrain_2 = select_ytraining_set[1]\n",
    "        ytrain_3 = select_ytraining_set[2]\n",
    "        ytrain_4 = select_ytraining_set[3]\n",
    "        yset_1 = np.append(ytrain_1,ytrain_2,axis=0)\n",
    "        yset_2 = np.append(yset_1,ytrain_3,axis=0)\n",
    "        ytraining_set = np.append(yset_2,ytrain_4,axis=0)\n",
    "        \n",
    "        #Selecting the x testing set i.e. the training set at the current index, and\n",
    "        #respective y training set\n",
    "        xtest_set = [test for i,test in enumerate(x_cv) if i==cv][0]\n",
    "        y_true = [test for i,test in enumerate(y_cv) if i==cv][0]\n",
    "        \n",
    "        #Train the model on the training data\n",
    "        my_model.fit(xtraining_set, ytraining_set, epochs=hyperparam['epochs_hyperparams'], batch_size=hyperparam['batch_size_hyperparams'])\n",
    "        \n",
    "        #Calculate f1\n",
    "        #Get the prediciton on the test set and reshape both y sets so that it would be 2D \n",
    "        #as sklearn's f1 evaluation only accepts 2D inputs. Just all the words and \n",
    "        #their corresponding targets, not split into sentences.\n",
    "        y_pred = my_model.predict(xtest_set)\n",
    "        yshape_true = y_true.shape\n",
    "        yshape_pred = y_pred.shape\n",
    "        y_true_newshape = (yshape_true[0]*yshape_true[1], yshape_true[-1])\n",
    "        y_pred_newshape = (yshape_pred[0]*yshape_pred[1], yshape_pred[-1])\n",
    "        y_true_reshaped = np.reshape(y_true, y_true_newshape)\n",
    "        y_pred_reshaped = np.reshape(y_pred, y_pred_newshape)\n",
    "        try:\n",
    "            temp_list.append(f1_score(y_true_reshaped, y_pred_reshaped, average = 'macro', labels=f1_labels))\n",
    "            print(param)\n",
    "            print(' ')\n",
    "            print(f1_score(y_true_reshaped, y_pred_reshaped, average = 'macro', labels=f1_labels))\n",
    "            print(' ')\n",
    "        except:\n",
    "            print('Predicted NaN')\n",
    "            print(' ')\n",
    "            temp_list.append(0)\n",
    "            \n",
    "        #On the first cross validation if the score is below 0.6 go to the next hyperparameter\n",
    "        if cv==0 and np.average(temp_list)<0.7:\n",
    "            break\n",
    "\n",
    "    calculated_f1 = np.average(temp_list)\n",
    "    print('F1 score')\n",
    "    print(param)\n",
    "    print(calculated_f1)\n",
    "    print(' ')\n",
    "    random_search_hist[hyperparam_number] = [hyperparam, calculated_f1, temp_list]\n",
    "    \n",
    "    #Dump the random_searh_dict in case of any unforseen circumstances to save progress\n",
    "    with open(random_search_hist_filepath, \"wb\") as t:\n",
    "        pickle.dump(random_search_hist, t)\n",
    "        \n",
    "    hyperparam_number+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameter_info = []\n",
    "for key,value in random_search_hist.items():\n",
    "    final_score = value[1]\n",
    "    if key==0:\n",
    "        best_hyperparameter_info = [final_score,random_search_hist[key][0]]\n",
    "    elif final_score > best_parameter_info[0]:\n",
    "        best_hyperparameter_info = [final_score,random_search_hist[key][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameter_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(best_hyperparams_info_filepath, \"wb\") as t:\n",
    "    pickle.dump(best_hyperparameter_info, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
