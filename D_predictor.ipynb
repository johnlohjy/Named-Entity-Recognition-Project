{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "curr_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_filepath = os.path.join(curr_dir,'word_vector','word_vector.txt').replace('\\\\','/')\n",
    "movie_queries_test_text_filepath = os.path.join(curr_dir,'test_set','movie_queries_test_text.txt').replace('\\\\','/')\n",
    "index_to_target_filepath = os.path.join(curr_dir,'index_converter','index_to_target.txt').replace('\\\\','/')\n",
    "target_to_index_filepath = os.path.join(curr_dir,'index_converter','target_to_index.txt').replace('\\\\','/')\n",
    "best_weights_filepath = os.path.join(curr_dir,'model_training_weights','weights.best.hdf5').replace('\\\\','/')\n",
    "best_hyperparams_info_filepath = os.path.join(curr_dir,'random_search_data','best_hyperparameter_info.txt').replace('\\\\','/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\User\\Miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.data import load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re \n",
    "from keras import backend as k\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, LSTM, Input, concatenate, TimeDistributed, Bidirectional, Masking\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.metrics import crf_viterbi_accuracy, crf_accuracy\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras.optimizers import Adam  \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, ParameterSampler, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You only need to run the cell below once, you can delete the cell below and across all notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Test Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(movie_queries_test_text_filepath, \"rb\") as t:\n",
    "    test_text = pickle.load(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "\n",
    "* Add the functions needed for cleaning the raw text\n",
    "* Set a dictionary for the index to be converted back into the target name once prediction has been done\n",
    "* Initialize the input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to remove . from numbers found using regex\n",
    "def remove_decimal(number):\n",
    "    return number.group(0).replace('.','')\n",
    "\n",
    "#Functions to remove , from numbers found using regex\n",
    "def remove_comma(number):\n",
    "    return number.group(0).replace(',','')\n",
    "\n",
    "#Define function to create base model dynamically\n",
    "#I used a dictionary and formatting to add hidden layers dynamically\n",
    "def base_model(units=50, optimizer='Adam', hidden_layers=2, activation_td ='relu', dropout=0.1, recurrent_dropout=0.1):\n",
    "    hidden_layers_stored = {}\n",
    "    counter=1\n",
    "    input = Input(shape=(80,95))\n",
    "    mask = Masking(mask_value=0.)(input)\n",
    "    for hl in range(hidden_layers):\n",
    "        if counter==1:\n",
    "            hidden_layers_stored['hl_{}'.format(counter)] = Bidirectional(LSTM(units=units, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout))(mask)  \n",
    "        else:\n",
    "            hidden_layers_stored['hl_{}'.format(counter)] = Bidirectional(LSTM(units=units, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout))(hidden_layers_stored['hl_{}'.format(counter-1)])\n",
    "        counter+=1\n",
    "    model_last_layer = TimeDistributed(Dense(50, activation=activation_td))(hidden_layers_stored['hl_{}'.format(counter-1)])  \n",
    "    crf = CRF(25)  \n",
    "    out = crf(model_last_layer)  \n",
    "    model_final = Model(input, out)\n",
    "    model_final.compile(optimizer=optimizer, loss=crf_loss, metrics=[crf_accuracy])\n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting best hyperparameters of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(best_hyperparams_info_filepath, \"rb\") as t:\n",
    "    best_hyperparameter_info = pickle.load(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing predictive model - graph, session, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Miniconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#GPU Options are added to prevent the program from taking up all the computer GPU's memory when initializing the model\n",
    "#for prediction\n",
    "graph_predictor = tf.Graph()\n",
    "with graph_predictor.as_default():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session_predictor = tf.Session(config=config)\n",
    "    with session_predictor.as_default():\n",
    "        model_predictor = base_model(units=best_hyperparameter_info[1]['units_hyperparams'],optimizer=best_hyperparameter_info[1]['optimizer_hyperparams'],hidden_layers=best_hyperparameter_info[1]['hidden_layers_hyperparams'],dropout=best_hyperparameter_info[1]['dropout_hyperparams'],recurrent_dropout=best_hyperparameter_info[1]['recurrent_dropout_hyperparams'])\n",
    "        model_predictor.load_weights(best_weights_filepath)\n",
    "        model_predictor._make_predict_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to convert index to categories - convert the vectors output from our predicted array to its respective target labels\n",
    "#so that it is readable\n",
    "with open(index_to_target_filepath, \"rb\") as t:\n",
    "    index_to_targets = pickle.load(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-ACTOR',\n",
       " 2: 'B-CHARACTER',\n",
       " 3: 'B-DIRECTOR',\n",
       " 4: 'B-GENRE',\n",
       " 5: 'B-PLOT',\n",
       " 6: 'B-RATING',\n",
       " 7: 'B-RATINGS_AVERAGE',\n",
       " 8: 'B-REVIEW',\n",
       " 9: 'B-SONG',\n",
       " 10: 'B-TITLE',\n",
       " 11: 'B-TRAILER',\n",
       " 12: 'B-YEAR',\n",
       " 13: 'I-ACTOR',\n",
       " 14: 'I-CHARACTER',\n",
       " 15: 'I-DIRECTOR',\n",
       " 16: 'I-GENRE',\n",
       " 17: 'I-PLOT',\n",
       " 18: 'I-RATING',\n",
       " 19: 'I-RATINGS_AVERAGE',\n",
       " 20: 'I-REVIEW',\n",
       " 21: 'I-SONG',\n",
       " 22: 'I-TITLE',\n",
       " 23: 'I-TRAILER',\n",
       " 24: 'I-YEAR'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize input_sequence\n",
    "input_sequence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all possible pos tags\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "all_pos = list(tagdict.keys())\n",
    "\n",
    "all_pos_tags = []\n",
    "for pos in all_pos:\n",
    "    all_pos_tags.append('pos_'+pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LS',\n",
       " 'TO',\n",
       " 'VBN',\n",
       " \"''\",\n",
       " 'WP',\n",
       " 'UH',\n",
       " 'VBG',\n",
       " 'JJ',\n",
       " 'VBZ',\n",
       " '--',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " 'DT',\n",
       " 'PRP',\n",
       " ':',\n",
       " 'WP$',\n",
       " 'NNPS',\n",
       " 'PRP$',\n",
       " 'WDT',\n",
       " '(',\n",
       " ')',\n",
       " '.',\n",
       " ',',\n",
       " '``',\n",
       " '$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'VBD',\n",
       " 'IN',\n",
       " 'FW',\n",
       " 'RP',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'PDT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'WRB',\n",
       " 'NNP',\n",
       " 'EX',\n",
       " 'NNS',\n",
       " 'SYM',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'POS']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input text to be extracted\n",
    "\n",
    "Here, I am using the test text provided by the MIT website which I have scraped. You may change this cell below this to a markdown cell and the cell that says \"Input a movie search query\" to a code cell if you wish to test using your own text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test_text[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text = \"Input a movie search query\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Numbers\n",
    "\n",
    "Decimal points from numbers will be removed during text cleaning as these decimal points could be mistaken as fullstops by the sentence tokenizer which would result in inaccurate sentence tokenization.\n",
    "\n",
    "The numbers list acts as a reference to replace the unformatted decimal numbers with their original format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'show me 1980s action movies'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find numbers\n",
    "text_find_numbers = text\n",
    "text_find_numbers = re.sub('[^a-zA-Z0-9.\\s]+','',text_find_numbers) \n",
    "numbers = re.findall('\\d*\\.?\\d+',text_find_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1980']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning for raw text\n",
    "\n",
    "Characters of words that are not letters, numbers or punctuation are removed as this will impact sentence tokenization,\n",
    "word tokenization and word vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text cleaning\n",
    "#Characters of words that are not letters, numbers or punctuation are removed as this will impact sentence tokenization,\n",
    "#word tokenization and word vectorization\n",
    "text = \" \".join(text.splitlines())\n",
    "text = re.sub('[^a-zA-Z0-9.,\\s]+','',text) \n",
    "text = re.sub('\\s+', ' ', text).strip()\n",
    "text = re.sub('\\d*\\.?\\d+',remove_decimal,text)\n",
    "text = re.sub('\\d*\\,?\\d+',remove_comma,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'show me 1980s action movies'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Break paragraph into sentences, then break sentence into words and add pos tags to each word of a sentence \n",
    "sentences = sent_tokenize(text)\n",
    "sent_num = 0\n",
    "pos_dict = {}\n",
    "for sentence in sentences:\n",
    "    sent_num += 1\n",
    "    pos_dict[sent_num] = nltk.pos_tag(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [('show', 'VB'),\n",
       "  ('me', 'PRP'),\n",
       "  ('1980s', 'CD'),\n",
       "  ('action', 'NN'),\n",
       "  ('movies', 'NNS')]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stray . , from words using re sub. If the word value of the tuple only contains . , then remove it\n",
    "for key,value in pos_dict.items():\n",
    "    cleaned = []\n",
    "    for pos_tuple in value:\n",
    "        word_value, tag_value = pos_tuple\n",
    "        checked = re.sub('[^a-zA-Z0-9]+','',word_value) \n",
    "        if len(checked)!=len(word_value):\n",
    "            print('Found stray punctuation')\n",
    "            print('Original: {}'.format(word_value))\n",
    "            print('New: {}'.format(checked))\n",
    "            print('')\n",
    "            print('#################')\n",
    "        if len(checked) == 0 :\n",
    "            continue\n",
    "        else:\n",
    "            pos_tuple = tuple([checked, tag_value])\n",
    "            cleaned.append(pos_tuple)\n",
    "\n",
    "    pos_dict[key] = cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [('show', 'VB'),\n",
       "  ('me', 'PRP'),\n",
       "  ('1980s', 'CD'),\n",
       "  ('action', 'NN'),\n",
       "  ('movies', 'NNS')]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe with corresponding sentence number, word, and part of speech columns\n",
    "L = [(k, *t) for k, v in pos_dict.items() for t in v]\n",
    "df = pd.DataFrame(L, columns=['sentence_no','word','pos'])\n",
    "\n",
    "#Use for later on\n",
    "df_for_prediction = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_no</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>show</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>me</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1980s</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>action</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>movies</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_no    word  pos\n",
       "0            1    show   VB\n",
       "1            1      me  PRP\n",
       "2            1   1980s   CD\n",
       "3            1  action   NN\n",
       "4            1  movies  NNS"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of words from dataframe\n",
    "tokenized_text = df['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['show', 'me', '1980s', 'action', 'movies']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call Word Vectorization API\n",
    "word_vector_api_data = tokenized_text\n",
    "session = requests.Session()\n",
    "session.trust_env = False\n",
    "session.post('http://127.0.0.1:5000/word_vectorization', json = word_vector_api_data) #add proxies args if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the processed word vectors\n",
    "with open(word_vectors_filepath, \"rb\") as t:\n",
    "    word_vectors = pickle.load(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add word featues to dataframe\n",
    "df['word_vec'] = word_vectors\n",
    "df = pd.get_dummies(df, columns=['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find pos columns needed to be added\n",
    "df_cols = list(df.columns)\n",
    "add_pos_col = [add for add in all_pos_tags if add not in df_cols]\n",
    "\n",
    "#Add missing pos columns\n",
    "for added_pos in add_pos_col:\n",
    "    df[added_pos] = 0\n",
    "\n",
    "#Rearrange columns in fixed order for consistency in training data set throughout all texts\n",
    "arrange_df_cols = ['sentence_no','word','word_vec']\n",
    "for arrange_pos in all_pos_tags:\n",
    "    arrange_df_cols.append(arrange_pos)\n",
    "df = df.reindex(columns=arrange_df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_no</th>\n",
       "      <th>word</th>\n",
       "      <th>word_vec</th>\n",
       "      <th>pos_LS</th>\n",
       "      <th>pos_TO</th>\n",
       "      <th>pos_VBN</th>\n",
       "      <th>pos_''</th>\n",
       "      <th>pos_WP</th>\n",
       "      <th>pos_UH</th>\n",
       "      <th>pos_VBG</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_MD</th>\n",
       "      <th>pos_VB</th>\n",
       "      <th>pos_WRB</th>\n",
       "      <th>pos_NNP</th>\n",
       "      <th>pos_EX</th>\n",
       "      <th>pos_NNS</th>\n",
       "      <th>pos_SYM</th>\n",
       "      <th>pos_CC</th>\n",
       "      <th>pos_CD</th>\n",
       "      <th>pos_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>show</td>\n",
       "      <td>[0.05406701, -0.15761112, -0.7017879, 0.234091...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>me</td>\n",
       "      <td>[0.44699496, -0.6717845, -1.0470167, 0.9299539...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1980s</td>\n",
       "      <td>[0.5675778, 0.09792379, -0.026658123, 0.374034...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>action</td>\n",
       "      <td>[0.31881523, -0.29548982, -0.08960247, 0.87853...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>movies</td>\n",
       "      <td>[0.2133574, -0.056065083, -1.0704498, 0.231683...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_no    word                                           word_vec  \\\n",
       "0            1    show  [0.05406701, -0.15761112, -0.7017879, 0.234091...   \n",
       "1            1      me  [0.44699496, -0.6717845, -1.0470167, 0.9299539...   \n",
       "2            1   1980s  [0.5675778, 0.09792379, -0.026658123, 0.374034...   \n",
       "3            1  action  [0.31881523, -0.29548982, -0.08960247, 0.87853...   \n",
       "4            1  movies  [0.2133574, -0.056065083, -1.0704498, 0.231683...   \n",
       "\n",
       "   pos_LS  pos_TO  pos_VBN  pos_''  pos_WP  pos_UH  pos_VBG  ...  pos_MD  \\\n",
       "0       0       0        0       0       0       0        0  ...       0   \n",
       "1       0       0        0       0       0       0        0  ...       0   \n",
       "2       0       0        0       0       0       0        0  ...       0   \n",
       "3       0       0        0       0       0       0        0  ...       0   \n",
       "4       0       0        0       0       0       0        0  ...       0   \n",
       "\n",
       "   pos_VB  pos_WRB  pos_NNP  pos_EX  pos_NNS  pos_SYM  pos_CC  pos_CD  pos_POS  \n",
       "0       1        0        0       0        0        0       0       0        0  \n",
       "1       0        0        0       0        0        0       0       0        0  \n",
       "2       0        0        0       0        0        0       0       1        0  \n",
       "3       0        0        0       0        0        0       0       0        0  \n",
       "4       0        0        0       0        1        0       0       0        0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the sentence feature vectors. Each sentence feature vector contains a list of all its word feature vectors.\n",
    "df = df.drop(columns=['word'])\n",
    "sentence_feature_vectors = {}\n",
    "for index,row in df.iterrows():\n",
    "    sentence_number = row[0]\n",
    "    word_feature_vector = np.concatenate((row[1:]), axis = None)\n",
    "    if sentence_number in sentence_feature_vectors.keys():\n",
    "        sentence_feature_vectors[sentence_number].append(word_feature_vector)\n",
    "    else:\n",
    "        sentence_feature_vectors[sentence_number] = [word_feature_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [array([ 0.05406701, -0.15761112, -0.7017879 ,  0.23409137,  0.49511296,\n",
       "          0.5845138 , -0.21149723,  0.41470313, -0.66746515,  0.3139659 ,\n",
       "         -0.22264327, -0.06002229, -0.26404837,  0.11272451, -0.07870636,\n",
       "         -0.00662771, -0.09953663,  0.19331707, -0.65225816, -0.23743977,\n",
       "          0.22146857,  0.44456705, -0.10762705, -0.02459927,  0.39042968,\n",
       "          0.2107949 ,  0.09701276, -0.1647754 , -0.3796033 ,  0.01939271,\n",
       "         -0.23600912,  0.01130283,  0.2009593 ,  0.05590365,  0.0929635 ,\n",
       "         -0.14136171,  0.04371291, -0.08660819,  0.02132413, -0.14475128,\n",
       "          0.7776699 , -0.3512436 , -0.50120497, -0.04874106,  0.31615117,\n",
       "         -0.07757556,  0.19927543, -0.15894759, -0.02038171,  0.16272163,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32),\n",
       "  array([ 0.44699496, -0.6717845 , -1.0470167 ,  0.92995393, -0.10248423,\n",
       "          0.8949343 ,  0.39631328,  0.22533202, -0.66176915, -0.1462245 ,\n",
       "          0.02872628, -0.23922561, -0.22937296,  0.03624375, -0.5052964 ,\n",
       "         -0.2541201 , -0.01356843,  0.11251163, -0.44821602, -0.4158126 ,\n",
       "         -0.01115775, -0.05475885, -0.14416292,  0.03886056, -0.5662192 ,\n",
       "         -0.29925346,  0.15953743, -0.12197897, -0.55408406,  0.29040962,\n",
       "         -0.37411344,  0.0232027 ,  0.19074468,  0.27253956, -0.18640043,\n",
       "          0.00739201,  0.17081603, -0.1073137 ,  0.39374727, -0.19592603,\n",
       "          0.06041001,  0.02363936, -0.41061538,  0.16293938, -0.24179415,\n",
       "          0.03628002,  0.3457169 , -0.00390303, -0.12349886,  0.04952596,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32),\n",
       "  array([ 0.5675778 ,  0.09792379, -0.02665812,  0.37403497, -0.7632306 ,\n",
       "         -0.12687328, -0.07102956, -0.22448592,  0.01379967, -0.17847537,\n",
       "         -0.03584633, -0.05316012,  0.00124046, -0.07511359,  0.1879499 ,\n",
       "          0.01061293, -0.09310209,  0.22149208,  0.27017477, -0.29835832,\n",
       "         -0.14073198,  0.19837052, -0.19875173,  0.20005208, -0.29480726,\n",
       "         -0.095013  , -0.11571279, -0.23327363, -0.210112  ,  0.41564834,\n",
       "         -0.19960208,  0.607368  ,  0.24449544,  0.076914  , -0.1404031 ,\n",
       "         -0.01399096,  0.03838731, -0.37380195,  0.20772833, -0.07716864,\n",
       "         -0.50380963,  0.13159354, -0.25482517,  0.05375935,  0.00488494,\n",
       "          0.3223139 ,  0.2751887 ,  0.2948895 , -0.15474725, -0.23783919,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  1.        ,  0.        ],\n",
       "        dtype=float32),\n",
       "  array([ 3.18815231e-01, -2.95489818e-01, -8.96024704e-02,  8.78530383e-01,\n",
       "          1.25502631e-01,  5.00742853e-01, -3.61035764e-01,  1.56486213e-01,\n",
       "         -5.55905551e-02,  7.24449381e-02,  3.57630461e-01, -1.74734771e-01,\n",
       "         -3.65821809e-01,  2.39302188e-01,  1.37389436e-01,  4.70179021e-01,\n",
       "          1.30395457e-01, -1.23860940e-01, -2.28679061e-01, -6.53362930e-01,\n",
       "         -2.06542641e-01, -6.29927017e-05, -2.49430574e-02,  1.88677460e-01,\n",
       "          1.41675353e-01,  2.40171432e-01,  1.63475960e-01, -1.05605744e-01,\n",
       "         -1.75210476e-01,  3.56129482e-02, -1.18694894e-01,  8.89236405e-02,\n",
       "         -6.31752908e-01,  3.73264402e-01,  2.14574009e-01,  1.01394050e-01,\n",
       "         -1.02426715e-01, -3.85422170e-01, -1.92730967e-02, -1.63221538e-01,\n",
       "          4.29340363e-01,  3.23061436e-01,  3.32237035e-02,  5.23745418e-01,\n",
       "          3.02517638e-02, -2.74168432e-01, -1.64929684e-02, -5.57229705e-02,\n",
       "         -4.70246263e-02, -2.94793576e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00], dtype=float32),\n",
       "  array([ 0.2133574 , -0.05606508, -1.0704498 ,  0.2316834 ,  0.3798532 ,\n",
       "          0.49244872, -0.01975853,  0.557269  , -1.0959971 ,  0.85555196,\n",
       "          0.32589266, -0.01742591, -0.512259  , -0.25030223, -0.02733061,\n",
       "          0.18721712, -0.11955133,  0.29936966, -0.7490547 ,  0.00479262,\n",
       "          0.46624565,  0.12122561, -0.00150538, -0.02670049,  0.627776  ,\n",
       "          0.8436455 , -0.02094151, -0.82160777, -0.10510147, -0.3571707 ,\n",
       "         -0.2553069 ,  0.08368087, -0.031499  , -0.00899041,  0.0264263 ,\n",
       "          0.26657948, -0.14786522, -0.21273485, -0.41336602,  0.02125849,\n",
       "          0.6711324 ,  0.29324383, -0.36484563,  0.5297395 ,  0.01324837,\n",
       "         -0.14479029,  0.40745825,  0.22255425, -0.0178736 ,  0.05635644,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          1.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32)]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad length for sentences and append to the input_sequence \n",
    "dummy_length = len(sentence_feature_vectors[1][0])\n",
    "for sentence in sentence_feature_vectors.values():\n",
    "    while len(sentence) < 80:\n",
    "        sentence.append(np.array([0 for zero in range(dummy_length)]))\n",
    "        \n",
    "    input_sequence.append(np.array(sentence))\n",
    "\n",
    "x = np.array(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.05406701, -0.15761112, -0.70178789, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.44699496, -0.67178452, -1.04701674, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.56757778,  0.09792379, -0.02665812, ...,  0.        ,\n",
       "          1.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 80, 95)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for all entities \n",
    "\n",
    "`np.argmax` is used to get the index of the tag with the highest probability in the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without np argmax the output sequence is a 3D output where each word contains one hot encodings: (1, 80, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WITHOUT np.argmax\n",
    "with session_predictor.as_default():\n",
    "    result_dummy = model_predictor.predict(x)\n",
    "\n",
    "print('Without np argmax the output sequence is a 3D output where each word contains one hot encodings: {}'.format(result_dummy.shape))\n",
    "result_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With np argmax the output sequence is a 2D output where each word is an index: (1, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, 12,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict y values using x values and convert integer y to its correct entity. This is for all the entities except for location\n",
    "with session_predictor.as_default():\n",
    "    prediction = np.argmax(model_predictor.predict(x), axis=-1)\n",
    "    \n",
    "print('With np argmax the output sequence is a 2D output where each word is an index: {}'.format(prediction.shape))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the index to its respective target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the index of the prediction to its respective target tag\n",
    "predicted_tag = [[index_to_targets[i] for i in row] for row in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['O',\n",
       "  'O',\n",
       "  'B-YEAR',\n",
       "  'B-GENRE',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Now that we have the predicted tags we need to get their respective words by getting the word in the same position as the target in its array\n",
    "\n",
    "#### Create a list of lists of the words that has the same shape as predicted_tag list of lists\n",
    "\n",
    "#### Create a dictionary where each key is a sentence number and each value is the words of that sentence\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary with sentence number as keys and the values as the words of the sentence \n",
    "sentences = {}\n",
    "\n",
    "for index,row in df_for_prediction.iterrows():\n",
    "    sentence_number = row[0]\n",
    "    word = row[1]\n",
    "    if sentence_number in sentences.keys():\n",
    "        sentences[sentence_number].append(word)\n",
    "    else:\n",
    "        sentences[sentence_number] = [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['show', 'me', '1980s', 'action', 'movies']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Add padding to each word list as the prediction contains padding too\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sequence = []\n",
    "for sentence in sentences.values():\n",
    "    while len(sentence) < 80:\n",
    "        sentence.append('padding')\n",
    "    word_sequence.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['show',\n",
       "  'me',\n",
       "  '1980s',\n",
       "  'action',\n",
       "  'movies',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Adding formatting back to numbers that are supposed to have decimal points\n",
    "\n",
    "However, some words may still be attached to numbers such as '4th' as recognized by the word tokenizer and so we should not separate it. The same goes for numbers such as '200+'. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "    re.findall('\\d*\\.?\\d+',word)\n",
    "``` \n",
    "searches for a number in the current word \n",
    "\n",
    "```python\n",
    "    re.search('[a-zA-Z+]', word)\n",
    "```\n",
    "searches for text and plus sign in the word. \n",
    "\n",
    "If both text and a plus sign are present in the number we do not replace anything\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outer loop loops over sentences\n",
    "#Inner loop loops over words in the sentence\n",
    "\n",
    "#Add decimal points back to numbers that have them\n",
    "\n",
    "#Counter for moving through numbers list\n",
    "counter = 0\n",
    "for sentence in word_sequence:\n",
    "    #Counter for tracking position of word in sentence\n",
    "    curr_index = 0\n",
    "    for word in sentence:\n",
    "        \n",
    "        #Check if all the formatted numbers have been iterated through\n",
    "        if counter < len(numbers):\n",
    "            \n",
    "            #If a number is found and it is equal to the number in \n",
    "            #the numbers list with the decimal point removed\n",
    "            if re.findall('\\d*\\.?\\d+',word) == [numbers[counter].replace('.','')]:\n",
    "                \n",
    "                #If a word or plus is found in the number do not replace anything, \n",
    "                #move on to the next number\n",
    "                if re.search('[a-zA-Z+]', word):\n",
    "                    counter+=1\n",
    "                else:\n",
    "                    #Replace the number with its correct formatting\n",
    "                    sentence.pop(curr_index)\n",
    "                    sentence.insert(curr_index, numbers[counter])\n",
    "                    counter += 1\n",
    "        curr_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['show',\n",
       "  'me',\n",
       "  '1980s',\n",
       "  'action',\n",
       "  'movies',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding',\n",
       "  'padding']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize an empty dictionary to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to convert categories to index\n",
    "with open(target_to_index_filepath, \"rb\") as t:\n",
    "    old_result_dict = pickle.load(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-ACTOR': 1,\n",
       " 'B-CHARACTER': 2,\n",
       " 'B-DIRECTOR': 3,\n",
       " 'B-GENRE': 4,\n",
       " 'B-PLOT': 5,\n",
       " 'B-RATING': 6,\n",
       " 'B-RATINGS_AVERAGE': 7,\n",
       " 'B-REVIEW': 8,\n",
       " 'B-SONG': 9,\n",
       " 'B-TITLE': 10,\n",
       " 'B-TRAILER': 11,\n",
       " 'B-YEAR': 12,\n",
       " 'I-ACTOR': 13,\n",
       " 'I-CHARACTER': 14,\n",
       " 'I-DIRECTOR': 15,\n",
       " 'I-GENRE': 16,\n",
       " 'I-PLOT': 17,\n",
       " 'I-RATING': 18,\n",
       " 'I-RATINGS_AVERAGE': 19,\n",
       " 'I-REVIEW': 20,\n",
       " 'I-SONG': 21,\n",
       " 'I-TITLE': 22,\n",
       " 'I-TRAILER': 23,\n",
       " 'I-YEAR': 24}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in old_result_dict.items():\n",
    "    old_result_dict[k]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': [],\n",
       " 'B-ACTOR': [],\n",
       " 'B-CHARACTER': [],\n",
       " 'B-DIRECTOR': [],\n",
       " 'B-GENRE': [],\n",
       " 'B-PLOT': [],\n",
       " 'B-RATING': [],\n",
       " 'B-RATINGS_AVERAGE': [],\n",
       " 'B-REVIEW': [],\n",
       " 'B-SONG': [],\n",
       " 'B-TITLE': [],\n",
       " 'B-TRAILER': [],\n",
       " 'B-YEAR': [],\n",
       " 'I-ACTOR': [],\n",
       " 'I-CHARACTER': [],\n",
       " 'I-DIRECTOR': [],\n",
       " 'I-GENRE': [],\n",
       " 'I-PLOT': [],\n",
       " 'I-RATING': [],\n",
       " 'I-RATINGS_AVERAGE': [],\n",
       " 'I-REVIEW': [],\n",
       " 'I-SONG': [],\n",
       " 'I-TITLE': [],\n",
       " 'I-TRAILER': [],\n",
       " 'I-YEAR': []}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize result dictionary\n",
    "old_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the respective words of the targets and storing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outer loop loops through sentences, inner loop loops through the sentence\n",
    "\n",
    "Getting the corresponding word of the target now that both arrays have the exact same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted tag found: B-YEAR\n",
      "Its position in the word sequence is\n",
      "    Sentence Number: 0 , Index: 2\n",
      "Added word: 1980s from word sequence using subsets 0, 2\n",
      " \n",
      "Predicted tag found: B-GENRE\n",
      "Its position in the word sequence is\n",
      "    Sentence Number: 0 , Index: 3\n",
      "Added word: action from word sequence using subsets 0, 3\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Outer loop loops through sentences, Inner loop loops through the sentence\n",
    "\n",
    "#Set sentence counter to 0\n",
    "sent_counter = 0\n",
    "\n",
    "#Iterating over sentences\n",
    "for sentence_prediction in predicted_tag:\n",
    "    \n",
    "    #set word counter to 0\n",
    "    word_counter = 0\n",
    "    for single_prediction in sentence_prediction:\n",
    "        #if the target is not O\n",
    "        if single_prediction != 'O':\n",
    "            \n",
    "            print('Predicted tag found: {}'.format(single_prediction))\n",
    "            print('Its position in the word sequence is')\n",
    "            print('    Sentence Number: {} , Index: {}'.format(sent_counter,word_counter))\n",
    "            \n",
    "            #Add the corresponding word of the predicted label to the old_result_dict using the correct subsets\n",
    "            old_result_dict[single_prediction].append(word_sequence[sent_counter][word_counter])\n",
    "            \n",
    "            print('Added word: {} from word sequence using subsets {}, {}'.format(word_sequence[sent_counter][word_counter],sent_counter,word_counter))\n",
    "            print(' ')\n",
    "        \n",
    "        word_counter+=1\n",
    "    sent_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': [],\n",
       " 'B-ACTOR': [],\n",
       " 'B-CHARACTER': [],\n",
       " 'B-DIRECTOR': [],\n",
       " 'B-GENRE': ['action'],\n",
       " 'B-PLOT': [],\n",
       " 'B-RATING': [],\n",
       " 'B-RATINGS_AVERAGE': [],\n",
       " 'B-REVIEW': [],\n",
       " 'B-SONG': [],\n",
       " 'B-TITLE': [],\n",
       " 'B-TRAILER': [],\n",
       " 'B-YEAR': ['1980s'],\n",
       " 'I-ACTOR': [],\n",
       " 'I-CHARACTER': [],\n",
       " 'I-DIRECTOR': [],\n",
       " 'I-GENRE': [],\n",
       " 'I-PLOT': [],\n",
       " 'I-RATING': [],\n",
       " 'I-RATINGS_AVERAGE': [],\n",
       " 'I-REVIEW': [],\n",
       " 'I-SONG': [],\n",
       " 'I-TITLE': [],\n",
       " 'I-TRAILER': [],\n",
       " 'I-YEAR': []}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As each label has B-, I- tags, we need to consolidate the variations of the labels to its root label. i.e B-ACTOR and I-ACTOR should be considered as ACTOR.\n",
    "\n",
    "We iterate through the dictionary and extract out the root label, and add the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for k,v in old_result_dict.items():\n",
    "    if k!='O':\n",
    "        new_key = k.split('-')[1]\n",
    "    else:\n",
    "        new_key = 'O'\n",
    "    if new_key not in result_dict.keys():\n",
    "        result_dict[new_key] = v\n",
    "    else:\n",
    "        result_dict[new_key].extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': [],\n",
       " 'ACTOR': [],\n",
       " 'CHARACTER': [],\n",
       " 'DIRECTOR': [],\n",
       " 'GENRE': ['action'],\n",
       " 'PLOT': [],\n",
       " 'RATING': [],\n",
       " 'RATINGS_AVERAGE': [],\n",
       " 'REVIEW': [],\n",
       " 'SONG': [],\n",
       " 'TITLE': [],\n",
       " 'TRAILER': [],\n",
       " 'YEAR': ['1980s']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now join all the values in the arrays to make it cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_clean = {}\n",
    "for k,v in result_dict.items():\n",
    "    result_dict_clean[k] = \" \".join(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': '',\n",
       " 'ACTOR': '',\n",
       " 'CHARACTER': '',\n",
       " 'DIRECTOR': '',\n",
       " 'GENRE': 'action',\n",
       " 'PLOT': '',\n",
       " 'RATING': '',\n",
       " 'RATINGS_AVERAGE': '',\n",
       " 'REVIEW': '',\n",
       " 'SONG': '',\n",
       " 'TITLE': '',\n",
       " 'TRAILER': '',\n",
       " 'YEAR': '1980s'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame.from_dict(result_dict_clean, orient='index')\n",
    "result_df = result_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.replace(to_replace=[None], value='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>ACTOR</th>\n",
       "      <th>CHARACTER</th>\n",
       "      <th>DIRECTOR</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>PLOT</th>\n",
       "      <th>RATING</th>\n",
       "      <th>RATINGS_AVERAGE</th>\n",
       "      <th>REVIEW</th>\n",
       "      <th>SONG</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>TRAILER</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>action</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1980s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  O ACTOR CHARACTER DIRECTOR   GENRE PLOT RATING RATINGS_AVERAGE REVIEW SONG  \\\n",
       "0                             action                                           \n",
       "\n",
       "  TITLE TRAILER   YEAR  \n",
       "0                1980s  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
